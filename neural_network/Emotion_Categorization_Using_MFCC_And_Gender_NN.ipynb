{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Emotion Classification Neural Network Using MFCC and Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and labeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-855.3770751953125, -855.3770751953125, -855....</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-850.3917236328125, -850.435791015625, -850.4...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-849.78369140625, -848.8447265625, -848.56610...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-842.9385375976562, -843.2474975585938, -850....</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-911.1758422851562, -910.4053344726562, -905....</td>\n",
       "      <td>0</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mfcc  gender  emotion\n",
       "0  [-855.3770751953125, -855.3770751953125, -855....       0  neutral\n",
       "1  [-850.3917236328125, -850.435791015625, -850.4...       0  neutral\n",
       "2  [-849.78369140625, -848.8447265625, -848.56610...       0  neutral\n",
       "3  [-842.9385375976562, -843.2474975585938, -850....       0  neutral\n",
       "4  [-911.1758422851562, -910.4053344726562, -905....       0     calm"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = np.load(\"audio_data.npy\")\n",
    "labels = np.load(\"wav_labels.npy\")\n",
    "\n",
    "# labels: modality-vocal channel-emotion-emotional intensity-statement-repetition-actor\n",
    "# emotions: 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "# odd number actors = male, even = female\n",
    "\n",
    "# 1440 files: 24 speakers, 60 recordings per speaker\n",
    "audio_data = audio_data.reshape(1440, 9480)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1440):\n",
    "    #female = 1\n",
    "    #male = 0\n",
    "    if (labels[i][6]%2 == 0):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "\n",
    "    if (labels[i][2] == 1):\n",
    "        em = \"neutral\"\n",
    "    elif (labels[i][2] == 2):\n",
    "        em = \"calm\"\n",
    "    elif (labels[i][2] == 3):\n",
    "        em = \"happy\"\n",
    "    elif (labels[i][2] == 4):\n",
    "        em = \"sad\"\n",
    "    elif (labels[i][2] == 5):\n",
    "        em = \"angry\"\n",
    "    elif (labels[i][2] == 6):\n",
    "        em = \"fearful\"\n",
    "    elif (labels[i][2] == 7):\n",
    "        em = \"disgust\"\n",
    "    elif (labels[i][2] == 8):\n",
    "        em = \"surprised\"\n",
    "    \n",
    "    features.append([audio_data[i], label, em])\n",
    "\n",
    "\n",
    "    \n",
    "feature_df = pd.DataFrame(features, columns = [\"mfcc\", \"gender\", \"emotion\"])\n",
    "\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ===== Males ===== ##\n",
    "X = np.array(feature_df.mfcc.tolist())\n",
    "y = np.array(feature_df.emotion.tolist())\n",
    "\n",
    "#20-80 train-test split\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Predictions\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 15, 10), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classification\n",
      "   neutral  calm  happy  sad  angry  fearful  disgust  surprised\n",
      "0       23     1      5    0      4        0        0          1\n",
      "1        0    22      2    0      0        4       14          2\n",
      "2        3     2     19    1      0        0        3          3\n",
      "3        3     4      1   15     11        0        4          3\n",
      "4        2     1      2    2     17        2        3          4\n",
      "5        0     5      1    1      3        9        4          2\n",
      "6        2     4      0    5      5        1       18          3\n",
      "7        4     0      4    3      6        0        6         19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification by Gender Precision: 0.5114794809687713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.62      0.68      0.65        34\n",
      "        calm       0.56      0.50      0.53        44\n",
      "     disgust       0.56      0.61      0.58        31\n",
      "     fearful       0.56      0.37      0.44        41\n",
      "       happy       0.37      0.52      0.43        33\n",
      "     neutral       0.56      0.36      0.44        25\n",
      "         sad       0.35      0.47      0.40        38\n",
      "   surprised       0.51      0.45      0.48        42\n",
      "\n",
      "    accuracy                           0.49       288\n",
      "   macro avg       0.51      0.49      0.49       288\n",
      "weighted avg       0.51      0.49      0.49       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithm Evaluation\n",
    "print(\"Emotion Classification\")\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "df = pd.DataFrame(cm, columns=[y[0], y[4], y[12], y[20], y[28], y[36], y[44], y[52] ])\n",
    "print(df)\n",
    "      \n",
    "#figure for confusion matrix\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "#precision function\n",
    "def precision(confmatrix):\n",
    "    # precision = tp/(tp+fp)\n",
    "    tp = np.diag(confmatrix)\n",
    "    fp = np.sum(confmatrix, axis=0) - tp\n",
    "    precision = np.mean(tp/(tp+fp))\n",
    "    return precision\n",
    "\n",
    "#print calculated precision\n",
    "prec = precision(cm)\n",
    "print(\"Classification by Gender Precision: \" + str(prec))\n",
    "#print metrics report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

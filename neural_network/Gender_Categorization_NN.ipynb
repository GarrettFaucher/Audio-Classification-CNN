{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Gender Classification Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading labeled data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-855.3770751953125, -855.3770751953125, -855....</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-850.3917236328125, -850.435791015625, -850.4...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-849.78369140625, -848.8447265625, -848.56610...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-842.9385375976562, -843.2474975585938, -850....</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-911.1758422851562, -910.4053344726562, -905....</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mfcc gender\n",
       "0  [-855.3770751953125, -855.3770751953125, -855....   Male\n",
       "1  [-850.3917236328125, -850.435791015625, -850.4...   Male\n",
       "2  [-849.78369140625, -848.8447265625, -848.56610...   Male\n",
       "3  [-842.9385375976562, -843.2474975585938, -850....   Male\n",
       "4  [-911.1758422851562, -910.4053344726562, -905....   Male"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = np.load(\"audio_data.npy\")\n",
    "\n",
    "# 1440 files: 24 speakers, 60 recordings per speaker\n",
    "# alternate male/female so can accurately label gender of speaker with if statement below\n",
    "audio_data = audio_data.reshape(1440, 9480)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1440):\n",
    "    if (i<60 or (i>120 and i<180) or (i>240 and i<300) or (i>360 and i<420) or (i>480 and i<540) or\n",
    "        (i>600 and i<660) or (i>720 and i<780) or (i>840 and i<900) or (i>960 and i<1020) or (i>1080 and i<1140)\n",
    "        or (i>1200 and i<1260) or (i>1320 and i<1380)):\n",
    "        label = \"Male\" \n",
    "    else:\n",
    "        label = \"Female\"\n",
    "    \n",
    "    features.append([audio_data[i], label])\n",
    "\n",
    "\n",
    "    \n",
    "feature_df = pd.DataFrame(features, columns = [\"mfcc\", \"gender\"])\n",
    "\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split testing and training data\n",
    "X = np.array(feature_df.mfcc.tolist())\n",
    "Y = np.array(feature_df.gender.tolist())\n",
    "\n",
    "#20-80 train-test split\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Predictions\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5, 5, 5), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145   3]\n",
      " [  3 137]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAEICAYAAABxpmCnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS0ElEQVR4nO3df7BcZX3H8ffHhICJUUhiAkQQW6M2dUhKMwiikrSCJGKDHa0gDcjAZFTotIq1tDpo1XZER2sZQRqR8kvwJ5FUAiQ4dRApSmDygxSENISCNyUQMMgPgdhv/zjn2sPN7r17735zdk/8vGZ2dvc8z3P2Odnczz1n95z7VURgZpblRb2egJntWRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKofJbTNKLJf2bpB2Svt3Fek6WtCpzbr0g6XpJp/Z6Hk3nUGkASe+VtEbSk5K2lv/535Sw6ncBM4CpEfHusa4kIr4eEccmzOcFJM2XFJKuGbJ8Trn8hx2u55OSrhypX0QsjIjLxjhdKzlU+pykDwNfAv6RIgAOBi4EFies/pXAvRGxM2Fdu8sjwBslTa0sOxW4N+sFVPDPQpaI8K1Pb8DLgCeBdw/TZ2+K0Bkob18C9i7b5gMPAWcD24CtwGll298DzwHPl69xOvBJ4MrKug8BAhhfPn8fsBn4JXA/cHJl+S2VcW8Ebgd2lPdvrLT9EPg08ONyPauAaW22bXD+FwFnlsvGlcvOBX5Y6fvPwIPAE8AdwJvL5ccN2c51lXn8QzmPZ4BXl8vOKNu/Anynsv7zgB8A6vX/i36/OZ3725HAPsDyYfp8DDgCmAvMAQ4HPl5p358inGZSBMcFkvaLiE9Q7P18MyJeEhFfG24ikiYB5wMLI2IyRXCsbdFvCnBd2Xcq8EXguiF7Gu8FTgOmAxOAjwz32sDlwCnl47cBGykCtOp2in+DKcBVwLcl7RMRNwzZzjmVMUuApcBk4IEh6zsbOFTS+yS9meLf7tQoE8bac6j0t6nAozH84cnJwKciYltEPEKxB7Kk0v582f58RKyk+G392jHO53+B10t6cURsjYiNLfq8HbgvIq6IiJ0RcTVwD/COSp9/jYh7I+IZ4FsUYdBWRNwKTJH0WopwubxFnysjYnv5ml+g2IMbaTsvjYiN5Zjnh6zvaeDPKULxSuAvIuKhEdZnOFT63XZgmqTxw/Q5kBf+ln2gXPabdQwJpaeBl4x2IhHxFPAe4P3AVknXSXpdB/MZnNPMyvP/GcN8rgDOAhbQYs9N0tmS7i6/yfoFxd7ZtBHW+eBwjRHxU4rDPVGEn3XAodLf/gP4FXDCMH0GKD5wHXQwux4adOopYGLl+f7Vxoi4MSKOAQ6g2Pv4agfzGZzTz8c4p0FXAB8EVpZ7Eb9RHp78DfBnwH4RsS/F5zkanHqbdQ57KCPpTIo9ngHgo2Of+m8Xh0ofi4gdFB9IXiDpBEkTJe0laaGkz5XdrgY+LunlkqaV/Uf8+rSNtcBbJB0s6WXA3w42SJoh6U/Kz1aepTiM+nWLdawEXlN+DT5e0nuA2cD3xzgnACLifuBois+QhpoM7KT4pmi8pHOBl1baHwYOGc03PJJeA3yG4hBoCfBRScMeplnBodLnIuKLwIcpPnx9hGKX/Szge2WXzwBrgPXABuDOctlYXms18M1yXXfwwiB4EcWHlwPAYxQ/4B9ssY7twPFl3+0Uv+GPj4hHxzKnIeu+JSJa7YXdCFxP8TXzAxR7d9VDm8ET+7ZLunOk1ykPN68EzouIdRFxH/B3wBWS9u5mG34byB9mm1km76mYWaquQkXSFEmrJd1X3u/Xpt8WSRskrZW0ZrTjzaw5ut1TOQf4QUTMojjb8Jxh+i6IiLkRMW+M482sAbr6TEXSz4D5EbFV0gEUp03vcsKRpC3AvKEf1nU63syao9tQ+UV5TsDg88cjYpdDGEn3A49TnBfwLxGxbDTjy7alFKdUM2mi/vB1r54w5nlb/e5dP3HkTtY3fsVTPBfPauSeuxruTE0AJN3EkJOgSq3OF2jnqIgYkDQdWC3pnoi4eRTjKYNoGcC8OfvET288aDTDrcfedqBP8WiSn8QPxjx2xFCJiLe2a5P0sKQDKocv29qsY6C83yZpOcVFbzcDHY03s+bo9oPaFRR/24Ly/tqhHSRNkjR58DFwLHBXp+PNrFm6DZXPAsdIug84pnyOpAMlrSz7zABukbQO+ClwXXk5etvxZtZcIx7+DKc8JfuPWywfABaVjzdT/J2PjsebWXP5jFozS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUDhUzS+VQMbNUu73sqaSDJP27pLslbZT0l5W2T0r6eVkOda2kRd3Mx8x6r46ypzuBsyPi94AjgDMlza60/1NZDnVuRKxsMd7MGqTbUFkMXFY+vgw4YWiHiNgaEXeWj38J3A3M7PJ1zaxPdRsqMyJiKxThAUwfrrOkQ4A/AH5SWXyWpPWSLml1+GRmzTJiqEi6SdJdLW6LR/NCkl4CfBf4q4h4olz8FeB3gbnAVuALw4xfKmmNpDWPbP/1aF7azGpUS9lTSXtRBMrXI+KayrofrvT5KvD9YebxglrKI83bzHqjjrKnAr4G3B0RXxzSdkDl6Tv5/3KoZtZQdZQ9PQpYAvxRi6+OPydpg6T1wALgQ13Ox8x6rI6yp7cAajN+STevb2b9x2fUmlkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFmqlFCRdJykn0naJGmX0qcqnF+2r5d0WKdjzaxZug4VSeOAC4CFwGzgpCG1kinbZpW3pRRFxDoda2YNkrGncjiwKSI2R8RzwDcoaixXLQYuj8JtwL5lzZ9OxppZg2SEykzgwcrzh9i1AHu7Pp2MBVz21KwpMkKlVU2foWVJ2/XpZGyxMGJZRMyLiHkvnzpulFM0s7p0VUys9BBwUOX5K4CBDvtM6GCsmTVIxp7K7cAsSa+SNAE4kaLGctUK4JTyW6AjgB0RsbXDsWbWIF3vqUTETklnATcC44BLImKjpPeX7RcBKynKoG4CngZOG25st3Mys97JOPwhIlZSBEd12UWVxwGc2elYM2sun1FrZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWyqFiZqkcKmaWqq6ypyeX5U7XS7pV0pxK2xZJGyStlbQmYz5m1jtd/43aSunSYyhKcdwuaUVE/Gel2/3A0RHxuKSFwDLgDZX2BRHxaLdzMbPeq6XsaUTcGhGPl09vo6jvY2Z7oLrKnladDlxfeR7AKkl3SFrabpDLnpo1Q0aJjo5Ll0paQBEqb6osPioiBiRNB1ZLuicibt5lhRHLKA6bmDdnn5brN7Pey9hT6aTsKZIOBS4GFkfE9sHlETFQ3m8DllMcTplZQ9VS9lTSwcA1wJKIuLeyfJKkyYOPgWOBuxLmZGY9UlfZ03OBqcCFkgB2RsQ8YAawvFw2HrgqIm7odk5m1jt1lT09AzijxbjNwJyhy82suXxGrZmlcqiYWSqHipmlcqiYWSqHipmlcqiYWSqHipmlcqiYWSqHipmlcqiYWSqHipmlcqiYWSqHipmlcqiYWSqHipmlcqiYWSqHipmlcqiYWaq6yp7Ol7SjLG26VtK5nY41s2apq+wpwI8i4vgxjjWzhqil7OluGmtmfSjjr+m3Knv6hhb9jpS0jqLQ2EciYuMoxlKWRF0KsA8TeduBcxOmbnW58IFbej0FG4U/ffsvxzy2rrKndwKvjIgnJS0CvgfM6nBssbBS9vSlmuKyp2Z9qpaypxHxREQ8WT5eCewlaVonY82sWeoqe7q/yjKEkg4vX3d7J2PNrFnqKnv6LuADknYCzwAnRkQALcd2Oycz6526yp5+Gfhyp2PNrLl8Rq2ZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFmqusqe/nWl5Oldkn4taUrZtkXShrJtTcZ8zKx3ail7GhGfBz5f9n8H8KGIeKyymgUR8Wi3czGz3utF2dOTgKsTXtfM+lBGqLQqXTqzVUdJE4HjgO9WFgewStIdZWnTliQtlbRG0prneTZh2ma2O9RV9nTQO4AfDzn0OSoiBiRNB1ZLuicibt5lhS57atYItZQ9rTiRIYc+ETFQ3m8DllMcTplZQ9VS9hRA0suAo4FrK8smSZo8+Bg4FrgrYU5m1iN1lT0FeCewKiKeqgyfASwvyyyPB66KiBu6nZOZ9U4tZU/L55cClw5ZthmYkzEHM+sPPqPWzFI5VMwslUPFzFI5VMwslUPFzFI5VMwslUPFzFI5VMwslUPFzFI5VMwslUPFzFI5VMwslUPFzFI5VMwslUPFzFI5VMwslUPFzFI5VMwsVVbZ00skbZPU8o9Wq3B+WRZ1vaTDKm3Dlkw1s2bJ2lO5lKJIWDsLgVnlbSnwFXhBydSFwGzgJEmzk+ZkZj2QEipl8a/HhumyGLg8CrcB+0o6gNGXTDWzPlfXZyrtSqOOpmSqy56aNUBdodKuNGrHJVMjYllEzIuIeXuxd+rkzCxPSt2fDrQrjTqhzXIza6i69lRWAKeU3wIdAeyIiK10WDLVzJojZU9F0tXAfGCapIeATwB7wW8qFa4EFgGbgKeB08q2liVTM+ZkZr2RVfb0pBHaAzizTdsuJVPNrLl8Rq2ZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFkqh4qZpXKomFmqusqenlyWO10v6VZJcyptWyRtkLRW0pqM+ZhZ79RV9vR+4OiIOBT4NLBsSPuCiJgbEfOS5mNmPZL1h69vlnTIMO23Vp7eRlHfx8z2QL34TOV04PrK8wBWSbpD0tIezMfMEtVVoRAASQsoQuVNlcVHRcSApOnAakn3lAXfh45dCiwF2IeJtczXzEavtj0VSYcCFwOLI2L74PKIGCjvtwHLgcNbjXctZbNmqCVUJB0MXAMsiYh7K8snSZo8+Bg4Fmj5DZKZNUNdZU/PBaYCF0oC2Fl+0zMDWF4uGw9cFRE3ZMzJzHqjrrKnZwBntFi+GZiz6wgzayqfUWtmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqRwqZpbKoWJmqeqqpTxf0o6yXvJaSedW2o6T9DNJmySdkzEfM+udumopA/yorJc8NyI+BSBpHHABsBCYDZwkaXbSnMysB1JCpawo+NgYhh4ObIqIzRHxHPANYHHGnMysN+ose3qkpHXAAPCRiNgIzAQerPR5CHhDq8HVsqfAszfFd/bEomPTgEd7PYnd4TUH77Hbtqdu12vHOrCuULkTeGVEPClpEfA9YBagFn2j1QoiYhmwDEDSmrIY2R5lT90u2HO3bU/errGOreXbn4h4IiKeLB+vBPaSNI1iz+SgStdXUOzJmFlD1VVLeX+VtU0lHV6+7nbgdmCWpFdJmgCcCKyoY05mtnvUVUv5XcAHJO0EngFOjIgAdko6C7gRGAdcUn7WMpJlGfPuQ3vqdsGeu23eriFU/GybmeXwGbVmlsqhYmapGhEqkqZIWi3pvvJ+vzb9tkjaUF4KMOavxHa3kS5NUOH8sn29pMN6Mc/R6mC72l6u0c86uAylke8XdHeJTVsR0fc34HPAOeXjc4Dz2vTbAkzr9XxH2JZxwH8BvwNMANYBs4f0WQRcT3EezxHAT3o976Ttmg98v9dzHcO2vQU4DLirTXvj3q9RbNuo37NG7KlQnLp/Wfn4MuCEHs6lW51cmrAYuDwKtwH7Sjqg7omO0h57yUWMfBlKE98voKtLbNpqSqjMiIitAOX99Db9Algl6Y7ytP5+1OrShJlj6NNvOp3zkZLWSbpe0u/XM7Xdronv12iM6j2r89qfYUm6Cdi/RdPHRrGaoyJiQNJ0YLWke8ok7iedXJrQ8eULfaSTObe7XKPpmvh+dWrU71nf7KlExFsj4vUtbtcCDw/uTpb329qsY6C83wYsp9gl7zedXJrQxMsXRpxztL9co+ma+H51ZCzvWd+EyghWAKeWj08Frh3aQdIkSZMHHwPHAv14JXMnlyasAE4pv1U4AtgxePjXx0bcrmEu12i6Jr5fHRnLe9Y3hz8j+CzwLUmnA/8NvBtA0oHAxRGxCJgBLC+3fzxwVUTc0KP5thURLS9NkPT+sv0iYCXFNwqbgKeB03o13051uF3tLtfoax1chtK492tQF5fYtF9nA95TM2uQphz+mFlDOFTMLJVDxcxSOVTMLJVDxcxSOVTMLJVDxcxS/R86j1s6T9dn3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.98      0.98      0.98       148\n",
      "        Male       0.98      0.98      0.98       140\n",
      "\n",
      "    accuracy                           0.98       288\n",
      "   macro avg       0.98      0.98      0.98       288\n",
      "weighted avg       0.98      0.98      0.98       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithm Evaluation\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "#figure for confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,predictions)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(conf_matrix)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Emotion Classification Neural Network Using MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and labeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-855.3770751953125, -855.3770751953125, -855....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-850.3917236328125, -850.435791015625, -850.4...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-849.78369140625, -848.8447265625, -848.56610...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-842.9385375976562, -843.2474975585938, -850....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-911.1758422851562, -910.4053344726562, -905....</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mfcc  emotion\n",
       "0  [-855.3770751953125, -855.3770751953125, -855....  neutral\n",
       "1  [-850.3917236328125, -850.435791015625, -850.4...  neutral\n",
       "2  [-849.78369140625, -848.8447265625, -848.56610...  neutral\n",
       "3  [-842.9385375976562, -843.2474975585938, -850....  neutral\n",
       "4  [-911.1758422851562, -910.4053344726562, -905....     calm"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = np.load(\"audio_data.npy\")\n",
    "labels = np.load(\"wav_labels.npy\")\n",
    "\n",
    "# labels: modality-vocal channel-emotion-emotional intensity-statement-repetition-actor\n",
    "# emotions: 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "# odd number actors = male, even = female\n",
    "\n",
    "# 1440 files: 24 speakers, 60 recordings per speaker\n",
    "audio_data = audio_data.reshape(1440, 9480)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1440):\n",
    "    if (labels[i][2] == 1):\n",
    "        em = \"neutral\"\n",
    "    elif (labels[i][2] == 2):\n",
    "        em = \"calm\"\n",
    "    elif (labels[i][2] == 3):\n",
    "        em = \"happy\"\n",
    "    elif (labels[i][2] == 4):\n",
    "        em = \"sad\"\n",
    "    elif (labels[i][2] == 5):\n",
    "        em = \"angry\"\n",
    "    elif (labels[i][2] == 6):\n",
    "        em = \"fearful\"\n",
    "    elif (labels[i][2] == 7):\n",
    "        em = \"disgust\"\n",
    "    elif (labels[i][2] == 8):\n",
    "        em = \"surprised\"\n",
    "    \n",
    "    features.append([audio_data[i], em])\n",
    "\n",
    "\n",
    "    \n",
    "feature_df = pd.DataFrame(features, columns = [\"mfcc\", \"emotion\"])\n",
    "\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split testing and training data\n",
    "X = np.array(feature_df.mfcc.tolist())\n",
    "Y = np.array(feature_df.emotion.tolist())\n",
    "\n",
    "#20-80 train-test split\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Predictions\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 115, 10), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classification\n",
      "   neutral  calm  happy  sad  angry  fearful  disgust  surprised\n",
      "0       20     2      3    1      6        0        1          1\n",
      "1        0    17      5    0      3        5       14          0\n",
      "2        0     5     14    4      1        1        2          4\n",
      "3        1     3      2   20      8        2        1          4\n",
      "4        5     0      0    6     13        4        1          4\n",
      "5        0     3      0    2      7        7        4          2\n",
      "6        1     9      0    5      1        4       17          1\n",
      "7        4     2      1    9      4        0        3         19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification by Gender Precision: 0.4487758423883014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.65      0.59      0.62        34\n",
      "        calm       0.41      0.39      0.40        44\n",
      "     disgust       0.56      0.45      0.50        31\n",
      "     fearful       0.43      0.49      0.45        41\n",
      "       happy       0.30      0.39      0.34        33\n",
      "     neutral       0.30      0.28      0.29        25\n",
      "         sad       0.40      0.45      0.42        38\n",
      "   surprised       0.54      0.45      0.49        42\n",
      "\n",
      "    accuracy                           0.44       288\n",
      "   macro avg       0.45      0.44      0.44       288\n",
      "weighted avg       0.45      0.44      0.44       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithm Evaluation\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "print(\"Emotion Classification\")\n",
    "df = pd.DataFrame(cm, columns=[Y[0], Y[4], Y[12], Y[20], Y[28], Y[36], Y[44], Y[52] ])\n",
    "print(df)\n",
    "\n",
    "#figure for confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,predictions)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(conf_matrix)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "#precision function\n",
    "def precision(confmatrix):\n",
    "    # precision = tp/(tp+fp)\n",
    "    tp = np.diag(confmatrix)\n",
    "    fp = np.sum(confmatrix, axis=0) - tp\n",
    "    precision = np.mean(tp/(tp+fp))\n",
    "    return precision\n",
    "\n",
    "prec = precision(cm)\n",
    "\n",
    "#print calculated precision\n",
    "print(\"Classification by Gender Precision: \" + str(prec))\n",
    "#print metrics report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Emotion Classification Neural Network Using MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and labeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-855.3770751953125, -855.3770751953125, -855....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-850.3917236328125, -850.435791015625, -850.4...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-849.78369140625, -848.8447265625, -848.56610...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-842.9385375976562, -843.2474975585938, -850....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-911.1758422851562, -910.4053344726562, -905....</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mfcc  emotion\n",
       "0  [-855.3770751953125, -855.3770751953125, -855....  neutral\n",
       "1  [-850.3917236328125, -850.435791015625, -850.4...  neutral\n",
       "2  [-849.78369140625, -848.8447265625, -848.56610...  neutral\n",
       "3  [-842.9385375976562, -843.2474975585938, -850....  neutral\n",
       "4  [-911.1758422851562, -910.4053344726562, -905....     calm"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = np.load(\"audio_data.npy\")\n",
    "labels = np.load(\"wav_labels.npy\")\n",
    "\n",
    "# labels: modality-vocal channel-emotion-emotional intensity-statement-repetition-actor\n",
    "# emotions: 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "# odd number actors = male, even = female\n",
    "\n",
    "# 1440 files: 24 speakers, 60 recordings per speaker\n",
    "audio_data = audio_data.reshape(1440, 9480)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1440):\n",
    "    if (labels[i][2] == 1):\n",
    "        em = \"neutral\"\n",
    "    elif (labels[i][2] == 2):\n",
    "        em = \"calm\"\n",
    "    elif (labels[i][2] == 3):\n",
    "        em = \"happy\"\n",
    "    elif (labels[i][2] == 4):\n",
    "        em = \"sad\"\n",
    "    elif (labels[i][2] == 5):\n",
    "        em = \"angry\"\n",
    "    elif (labels[i][2] == 6):\n",
    "        em = \"fearful\"\n",
    "    elif (labels[i][2] == 7):\n",
    "        em = \"disgust\"\n",
    "    elif (labels[i][2] == 8):\n",
    "        em = \"surprised\"\n",
    "    \n",
    "    features.append([audio_data[i], em])\n",
    "\n",
    "\n",
    "    \n",
    "feature_df = pd.DataFrame(features, columns = [\"mfcc\", \"emotion\"])\n",
    "\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split testing and training data\n",
    "X = np.array(feature_df.mfcc.tolist())\n",
    "Y = np.array(feature_df.emotion.tolist())\n",
    "\n",
    "#20-80 train-test split\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Predictions\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  0  4  1  2  0  3  0]\n",
      " [ 1 16  1  1  0  4 19  2]\n",
      " [ 6  1 12  0  1  4  6  1]\n",
      " [ 2  2  0 21  7  1  5  3]\n",
      " [ 3  0  0  6 17  4  2  1]\n",
      " [ 0  6  1  0  4  6  6  2]\n",
      " [ 1  3  4  6  3  5 15  1]\n",
      " [ 4  1  3  9  7  3  1 14]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.59      0.71      0.64        34\n",
      "        calm       0.55      0.36      0.44        44\n",
      "     disgust       0.48      0.39      0.43        31\n",
      "     fearful       0.48      0.51      0.49        41\n",
      "       happy       0.41      0.52      0.46        33\n",
      "     neutral       0.22      0.24      0.23        25\n",
      "         sad       0.26      0.39      0.32        38\n",
      "   surprised       0.58      0.33      0.42        42\n",
      "\n",
      "    accuracy                           0.43       288\n",
      "   macro avg       0.45      0.43      0.43       288\n",
      "weighted avg       0.46      0.43      0.44       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithm Evaluation\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "#figure for confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,predictions)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(conf_matrix)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

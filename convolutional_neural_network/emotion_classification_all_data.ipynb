{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutional Neural Network Using Mel Spectrogram Classifying Gender"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                mfcc gender  emotion\n",
       "0  [-855.3770751953125, -855.3770751953125, -855....   Male        0\n",
       "1  [-850.3917236328125, -850.435791015625, -850.4...   Male        0\n",
       "2  [-849.78369140625, -848.8447265625, -848.56610...   Male        0\n",
       "3  [-842.9385375976562, -843.2474975585938, -850....   Male        0\n",
       "4  [-911.1758422851562, -910.4053344726562, -905....   Male        1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mfcc</th>\n      <th>gender</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-855.3770751953125, -855.3770751953125, -855....</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-850.3917236328125, -850.435791015625, -850.4...</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[-849.78369140625, -848.8447265625, -848.56610...</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[-842.9385375976562, -843.2474975585938, -850....</td>\n      <td>Male</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-911.1758422851562, -910.4053344726562, -905....</td>\n      <td>Male</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "audio_data = np.load(\"../data/audio_data.npy\")\n",
    "labels = np.load(\"../data/wav_labels.npy\")\n",
    "\n",
    "# labels: modality-vocal channel-emotion-emotional intensity-statement-repetition-actor\n",
    "# emotions: 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "# odd number actors = male, even = female\n",
    "\n",
    "# 1440 files: 24 speakers, 60 recordings per speaker\n",
    "audio_data = audio_data.reshape(1440, 9480)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1440):\n",
    "    \n",
    "    if (labels[i][6]%2 == 0):\n",
    "        label = \"Female\"\n",
    "    else:\n",
    "        label = \"Male\"\n",
    "\n",
    "    if (labels[i][2] == 1):\n",
    "        em = 0\n",
    "    elif (labels[i][2] == 2):\n",
    "        em = 1\n",
    "    elif (labels[i][2] == 3):\n",
    "        em = 2\n",
    "    elif (labels[i][2] == 4):\n",
    "        em = 3\n",
    "    elif (labels[i][2] == 5):\n",
    "        em = 4\n",
    "    elif (labels[i][2] == 6):\n",
    "        em = 5\n",
    "    elif (labels[i][2] == 7):\n",
    "        em = 6\n",
    "    elif (labels[i][2] == 8):\n",
    "        em = 7\n",
    "    \n",
    "    features.append([audio_data[i], label, em])\n",
    "    \n",
    "feature_df = pd.DataFrame(features, columns = [\"mfcc\", \"gender\", \"emotion\"])\n",
    "\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feature_df.mfcc.tolist())\n",
    "y = np.array(feature_df.emotion.tolist())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "#20-80 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for CNN input\n",
    "X_train = np.array([x.reshape( (20, 474, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (20, 474, 1) ) for x in X_test])\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train = np.array(to_categorical(y_train, 8))\n",
    "y_test = np.array(to_categorical(y_test, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (5,5), input_shape=X_test.shape[1:], kernel_regularizer=l2(l=0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(24, (4,4), kernel_regularizer=l2(l=0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(24, (3,3), kernel_regularizer=l2(l=0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 2.5460 - accuracy: 0.1998 - val_loss: 2.2844 - val_accuracy: 0.2986\n",
      "Epoch 2/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.1453 - accuracy: 0.3179 - val_loss: 1.9300 - val_accuracy: 0.3681\n",
      "Epoch 3/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.7799 - accuracy: 0.4468 - val_loss: 1.5940 - val_accuracy: 0.4861\n",
      "Epoch 4/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.5290 - accuracy: 0.5208 - val_loss: 1.6064 - val_accuracy: 0.4653\n",
      "Epoch 5/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.3645 - accuracy: 0.5718 - val_loss: 1.5126 - val_accuracy: 0.4792\n",
      "Epoch 6/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.2270 - accuracy: 0.6358 - val_loss: 1.4413 - val_accuracy: 0.5417\n",
      "Epoch 7/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.0822 - accuracy: 0.6829 - val_loss: 1.3294 - val_accuracy: 0.5833\n",
      "Epoch 8/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.0189 - accuracy: 0.6898 - val_loss: 1.3283 - val_accuracy: 0.5764\n",
      "Epoch 9/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.9096 - accuracy: 0.7508 - val_loss: 1.3699 - val_accuracy: 0.6111\n",
      "Epoch 10/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.8607 - accuracy: 0.7523 - val_loss: 1.3437 - val_accuracy: 0.6250\n",
      "Epoch 11/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7678 - accuracy: 0.7878 - val_loss: 1.2906 - val_accuracy: 0.6389\n",
      "Epoch 12/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7216 - accuracy: 0.8140 - val_loss: 1.2673 - val_accuracy: 0.6250\n",
      "Epoch 13/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6626 - accuracy: 0.8333 - val_loss: 1.3295 - val_accuracy: 0.6389\n",
      "Epoch 14/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5959 - accuracy: 0.8534 - val_loss: 1.2958 - val_accuracy: 0.6319\n",
      "Epoch 15/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5348 - accuracy: 0.8727 - val_loss: 1.4057 - val_accuracy: 0.6181\n",
      "Epoch 16/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4964 - accuracy: 0.8943 - val_loss: 1.4944 - val_accuracy: 0.6389\n",
      "Epoch 17/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4727 - accuracy: 0.8912 - val_loss: 1.4425 - val_accuracy: 0.6875\n",
      "Epoch 18/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4542 - accuracy: 0.9097 - val_loss: 1.5552 - val_accuracy: 0.6111\n",
      "Epoch 19/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4504 - accuracy: 0.9120 - val_loss: 1.3470 - val_accuracy: 0.6528\n",
      "Epoch 20/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4033 - accuracy: 0.9236 - val_loss: 1.5210 - val_accuracy: 0.6458\n",
      "Epoch 21/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3807 - accuracy: 0.9383 - val_loss: 1.4296 - val_accuracy: 0.6597\n",
      "Epoch 22/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3562 - accuracy: 0.9452 - val_loss: 1.5085 - val_accuracy: 0.6528\n",
      "Epoch 23/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3335 - accuracy: 0.9491 - val_loss: 1.4291 - val_accuracy: 0.6736\n",
      "Epoch 24/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3113 - accuracy: 0.9576 - val_loss: 1.6543 - val_accuracy: 0.6458\n",
      "Epoch 25/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3112 - accuracy: 0.9514 - val_loss: 1.7177 - val_accuracy: 0.6181\n",
      "Epoch 26/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3157 - accuracy: 0.9576 - val_loss: 1.4736 - val_accuracy: 0.6528\n",
      "Epoch 27/40\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3287 - accuracy: 0.9468 - val_loss: 1.4728 - val_accuracy: 0.7153\n",
      "Epoch 28/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3389 - accuracy: 0.9429 - val_loss: 1.4147 - val_accuracy: 0.6667\n",
      "Epoch 29/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3008 - accuracy: 0.9529 - val_loss: 1.6320 - val_accuracy: 0.6389\n",
      "Epoch 30/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2874 - accuracy: 0.9568 - val_loss: 1.6611 - val_accuracy: 0.6597\n",
      "Epoch 31/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2821 - accuracy: 0.9576 - val_loss: 1.5924 - val_accuracy: 0.6875\n",
      "Epoch 32/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2525 - accuracy: 0.9799 - val_loss: 1.7274 - val_accuracy: 0.6944\n",
      "Epoch 33/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2729 - accuracy: 0.9622 - val_loss: 1.6411 - val_accuracy: 0.6667\n",
      "Epoch 34/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2603 - accuracy: 0.9660 - val_loss: 1.4923 - val_accuracy: 0.6944\n",
      "Epoch 35/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2369 - accuracy: 0.9799 - val_loss: 1.5315 - val_accuracy: 0.6944\n",
      "Epoch 36/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2290 - accuracy: 0.9722 - val_loss: 1.5928 - val_accuracy: 0.6806\n",
      "Epoch 37/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2109 - accuracy: 0.9830 - val_loss: 1.4552 - val_accuracy: 0.6667\n",
      "Epoch 38/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2149 - accuracy: 0.9792 - val_loss: 1.4620 - val_accuracy: 0.6806\n",
      "Epoch 39/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2076 - accuracy: 0.9838 - val_loss: 1.4426 - val_accuracy: 0.6944\n",
      "Epoch 40/40\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2044 - accuracy: 0.9807 - val_loss: 1.5230 - val_accuracy: 0.6667\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.5230 - accuracy: 0.6667\n",
      "Test loss: 1.5230028629302979\n",
      "Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "\toptimizer=\"Adam\",\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "\tx=X_train,\n",
    "\ty=y_train,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    validation_data= (X_test, y_test)\n",
    ")\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
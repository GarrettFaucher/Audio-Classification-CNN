{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutional Neural Network Using Mel Spectrogram Classifying Gender"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            mel_spec  gender  emotion\n",
       "0  [1.0769573011160105e-09, 2.8049595979240394e-1...       0      1.0\n",
       "1  [8.10519740213067e-09, 2.3336452770195137e-09,...       0      1.0\n",
       "2  [1.8761321030069666e-07, 2.7834460070153e-07, ...       0      1.0\n",
       "3  [1.213315243830948e-07, 1.1905444097237705e-07...       0      1.0\n",
       "4  [6.763266924281197e-08, 1.9553900187929685e-07...       0      2.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mel_spec</th>\n      <th>gender</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1.0769573011160105e-09, 2.8049595979240394e-1...</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[8.10519740213067e-09, 2.3336452770195137e-09,...</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1.8761321030069666e-07, 2.7834460070153e-07, ...</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[1.213315243830948e-07, 1.1905444097237705e-07...</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[6.763266924281197e-08, 1.9553900187929685e-07...</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "audio_data = np.load(\"../data/audio_data_mel_spec.npy\")\n",
    "labels = np.load(\"../data/wav_labels.npy\")\n",
    "\n",
    "# labels: modality-vocal channel-emotion-emotional intensity-statement-repetition-actor\n",
    "# emotions: 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "# odd number actors = male, even = female\n",
    "\n",
    "# 1440 files: 24 speakers, 60 recordings per speaker\n",
    "audio_data = audio_data.reshape(1440, 16384)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1440):\n",
    "    #female = 1\n",
    "    #male = 0\n",
    "    if (labels[i][6]%2 == 0):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    \n",
    "    features.append([audio_data[i], label, labels[i][2]])\n",
    "\n",
    "    \n",
    "feature_df = pd.DataFrame(features, columns = [\"mel_spec\", \"gender\", \"emotion\"])\n",
    "\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1152, 16384)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "## ===== Males ===== ##\n",
    "X = np.array(feature_df.mel_spec.tolist())\n",
    "y = np.array(feature_df.gender.tolist())\n",
    "\n",
    "#20-80 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for CNN input\n",
    "X_train = np.array([x.reshape( (128, 128, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 128, 1) ) for x in X_test])\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train = np.array(to_categorical(y_train, 2))\n",
    "y_test = np.array(to_categorical(y_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(128, 128, 1)\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "9/9 [==============================] - 7s 784ms/step - loss: 1.5148 - accuracy: 0.5408 - val_loss: 0.7971 - val_accuracy: 0.5660\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 7s 761ms/step - loss: 1.0718 - accuracy: 0.5425 - val_loss: 0.7388 - val_accuracy: 0.6146\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 7s 733ms/step - loss: 0.9266 - accuracy: 0.6016 - val_loss: 0.6671 - val_accuracy: 0.6042\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 7s 736ms/step - loss: 0.7064 - accuracy: 0.5833 - val_loss: 0.6772 - val_accuracy: 0.6319\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 8s 903ms/step - loss: 0.6878 - accuracy: 0.5816 - val_loss: 0.6578 - val_accuracy: 0.6181\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 7s 740ms/step - loss: 0.6531 - accuracy: 0.5929 - val_loss: 0.6769 - val_accuracy: 0.6042\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 7s 730ms/step - loss: 0.6426 - accuracy: 0.6033 - val_loss: 0.6974 - val_accuracy: 0.6007\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 7s 772ms/step - loss: 0.6450 - accuracy: 0.6198 - val_loss: 0.6672 - val_accuracy: 0.6458\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 7s 778ms/step - loss: 0.6350 - accuracy: 0.6345 - val_loss: 0.6683 - val_accuracy: 0.6562\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 7s 764ms/step - loss: 0.6190 - accuracy: 0.6736 - val_loss: 0.6893 - val_accuracy: 0.6979\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 7s 760ms/step - loss: 0.5873 - accuracy: 0.7049 - val_loss: 0.6788 - val_accuracy: 0.7014\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 7s 741ms/step - loss: 0.5857 - accuracy: 0.7066 - val_loss: 0.5923 - val_accuracy: 0.6944\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 7s 734ms/step - loss: 0.5836 - accuracy: 0.7083 - val_loss: 0.5546 - val_accuracy: 0.7326\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 7s 734ms/step - loss: 0.5698 - accuracy: 0.7066 - val_loss: 0.6169 - val_accuracy: 0.7083\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 7s 760ms/step - loss: 0.5951 - accuracy: 0.7092 - val_loss: 0.6665 - val_accuracy: 0.7049\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 7s 753ms/step - loss: 0.5272 - accuracy: 0.7222 - val_loss: 0.5990 - val_accuracy: 0.7083\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 7s 785ms/step - loss: 0.5212 - accuracy: 0.7474 - val_loss: 0.5572 - val_accuracy: 0.7431\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 7s 723ms/step - loss: 0.4897 - accuracy: 0.7604 - val_loss: 0.6740 - val_accuracy: 0.7431\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 7s 744ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.5978 - val_accuracy: 0.7535\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 7s 800ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 7s 811ms/step - loss: 0.4724 - accuracy: 0.7934 - val_loss: 0.7744 - val_accuracy: 0.7674\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 7s 744ms/step - loss: 0.4564 - accuracy: 0.7908 - val_loss: 0.4989 - val_accuracy: 0.7951\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 6s 698ms/step - loss: 0.4504 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.8021\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 7s 739ms/step - loss: 0.4533 - accuracy: 0.8273 - val_loss: 0.7017 - val_accuracy: 0.7222\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 6s 715ms/step - loss: 0.5129 - accuracy: 0.7630 - val_loss: 0.4385 - val_accuracy: 0.8021\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 7s 748ms/step - loss: 0.4489 - accuracy: 0.7839 - val_loss: 0.4274 - val_accuracy: 0.8090\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 7s 745ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.8125\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 8s 850ms/step - loss: 0.3699 - accuracy: 0.8238 - val_loss: 0.3480 - val_accuracy: 0.8507\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 7s 821ms/step - loss: 0.3447 - accuracy: 0.8533 - val_loss: 0.4008 - val_accuracy: 0.8611\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 7s 730ms/step - loss: 0.3412 - accuracy: 0.8646 - val_loss: 0.3034 - val_accuracy: 0.8819\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 7s 739ms/step - loss: 0.4051 - accuracy: 0.8438 - val_loss: 0.3708 - val_accuracy: 0.8785\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 6s 718ms/step - loss: 0.4331 - accuracy: 0.8168 - val_loss: 0.4813 - val_accuracy: 0.7778\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 7s 743ms/step - loss: 0.4415 - accuracy: 0.8168 - val_loss: 0.3211 - val_accuracy: 0.8889\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 8s 864ms/step - loss: 0.4143 - accuracy: 0.8559 - val_loss: 0.3175 - val_accuracy: 0.8889\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 7s 753ms/step - loss: 0.3382 - accuracy: 0.8550 - val_loss: 0.4084 - val_accuracy: 0.8576\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 7s 735ms/step - loss: 0.2743 - accuracy: 0.8785 - val_loss: 0.3852 - val_accuracy: 0.8889\n",
      "Epoch 37/40\n",
      "9/9 [==============================] - 7s 777ms/step - loss: 0.2839 - accuracy: 0.8845 - val_loss: 0.2644 - val_accuracy: 0.9236\n",
      "Epoch 38/40\n",
      "9/9 [==============================] - 7s 783ms/step - loss: 0.2334 - accuracy: 0.9097 - val_loss: 0.3141 - val_accuracy: 0.8819\n",
      "Epoch 39/40\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.2194 - accuracy: 0.9089 - val_loss: 0.1825 - val_accuracy: 0.9340\n",
      "Epoch 40/40\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1929 - accuracy: 0.9340 - val_loss: 0.1637 - val_accuracy: 0.9410\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.1637 - accuracy: 0.9410\n",
      "Test loss: 0.16367489099502563\n",
      "Test accuracy: 0.9409722089767456\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "\toptimizer=\"Adam\",\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "\tx=X_train,\n",
    "\ty=y_train,\n",
    "    epochs=40,\n",
    "    batch_size=128,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}